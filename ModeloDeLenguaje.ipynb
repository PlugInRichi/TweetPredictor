{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b719c6a5",
   "metadata": {},
   "source": [
    "# Definición de la Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0387c82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "70ddd2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModeloB:\n",
    "    \n",
    "    def __init__(self, dim_in  = 2, h_layers = [3 , 5], dim_out = 2, lr = 0.02):\n",
    "        np.random.seed(505) #Establecida para experimentación\n",
    "        random.seed(505)\n",
    "        self.dim_in  = dim_in # Dimensión de la entrada\n",
    "        self.dim_h_layers = len(h_layers) # Número de capas ocultas\n",
    "        self.dim_out = dim_out # Dimensión capa de salida\n",
    "\n",
    "        self.lr = lr #Learning Reate\n",
    "\n",
    "        self.layers = h_layers\n",
    "        \n",
    "        self.layers.insert(0,dim_in)\n",
    "        self.layers.append(dim_out)\n",
    "\n",
    "        self.ident = lambda x : x\n",
    "        self.tanh = lambda x : np.tanh(x)\n",
    "        self.soft_max = lambda x : np.exp(x - np.max(x))/np.exp(x - np.max(x)).sum(0, keepdims=True) #Cero porque son vectores columna\n",
    "\n",
    "        self.weigths = list() \n",
    "        self.bias = list()\n",
    "        self.Hs = list()\n",
    "\n",
    "        for k in range(self.dim_h_layers + 1):\n",
    "            self.weigths.append(np.random.rand(self.layers[k+1],self.layers[k])/np.sqrt(self.layers[k+1]))#Pa que converja rápido\n",
    "            self.bias.append(np.ones((self.layers[k+1],1)))\n",
    "            self.Hs.append(np.zeros((self.layers[k+1],1)))\n",
    "\n",
    "    def _backward(self,y_idx,x_idx):\n",
    "        y = np.zeros((self.sizeVocaculary,1))\n",
    "        y[y_idx] = 1\n",
    "\n",
    "        d_salida = self.Hs[-1] - y\n",
    "        d_hidden =(1 - self.Hs[-2]**2) * np.dot(self.weigths[-1].T,d_salida)\n",
    "        d_embedd =  np.dot(self.weigths[-2].T,d_hidden)\n",
    "\n",
    "        #Actualización de pesos\n",
    "        self.weigths[-1] -=  self.lr * np.outer(d_salida,self.Hs[-2])\n",
    "        self.weigths[-2] -=  self.lr * np.outer(d_hidden,self.Hs[-3])\n",
    "        self.weigths[-3][:,x_idx] -= self.lr * d_embedd.reshape(-1) \n",
    "\n",
    "        #Actualización de bias\n",
    "        self.bias[-1] = self.bias[-1] - self.lr * d_salida\n",
    "        self.bias[-2] = self.bias[-2] - self.lr * d_hidden\n",
    "\n",
    "    def _fordward(self, x):\n",
    "        #Obtiene el embedding\n",
    "        self.Hs[0] = self.weigths[0][:,x].reshape((100,1))\n",
    "        #Capa oculta\n",
    "        self.Hs[1] = self.tanh(np.dot(self.weigths[1],self.Hs[0]) + self.bias[1])\n",
    "        #Predicción\n",
    "        self.Hs[2] = self.soft_max(np.dot(self.weigths[2],self.Hs[1]) + self.bias[2])\n",
    "        \n",
    "    def train(self, epochs = 5):\n",
    "        for epoch in range(epochs):\n",
    "            for split in range(0,self.split):\n",
    "                train_split, validation_split =  self.getTrainValidSplits(split)\n",
    "                count = 0\n",
    "                for k in train_split:\n",
    "                    x = self.bigrams[k][0]\n",
    "                    y = self.bigrams[k][1]\n",
    "                    self._fordward(x)\n",
    "                    self._backward(y,x)\n",
    "                    count += 1 \n",
    "                    if (count%5000 == 0):\n",
    "                        print('Epoch:', epoch ,' fold: ',split+1,' iteración: ',count,' / ',len(train_split))    \n",
    "                #self.validation(validation_split)\n",
    "                \n",
    "            \n",
    "    def validation(self,validation_split):\n",
    "        sizeValid = len(validation_split)\n",
    "        prediciones = np.zeros(sizeValid) \n",
    "        for k,i in zip(validation_split,range(sizeValid)): #K es muestra\n",
    "            x = self.bigrams[k][0]\n",
    "            y = self.bigrams[k][1]\n",
    "            self._fordward(x)\n",
    "            prediciones[i] = self.Hs[2][y]\n",
    "        self.prediciones = prediciones #Solo para debbug\n",
    "        self.perplejidad.append(np.prod(1/prediciones)**(1/sizeValid))\n",
    "        print(\"Perplejidad: \",self.perplejidad[-1],\"\\n\")\n",
    "        \n",
    "        \n",
    "    def predic(self, x):\n",
    "        self._fordward(x)\n",
    "        return self.Hs[2]\n",
    "        \n",
    "    def loadData(self, bigrams, sizeVocaculary):\n",
    "        self.bigrams = bigrams\n",
    "        self.sizeData = len(bigrams)\n",
    "        self.sizeVocaculary = sizeVocaculary\n",
    "        self.buildTrainValidationSplits(bigrams, 5)\n",
    "        \n",
    "    def buildTrainValidationSplits(self, bigrams, numsplit = 5):\n",
    "        self.indexes = [i for i in range (len (bigrams))]\n",
    "        random.shuffle(self.indexes)  \n",
    "        self.split = numsplit\n",
    "        self.sizeSplit = len(bigrams)//numsplit\n",
    "        self.validation_r = [i for i in range(self.split)]\n",
    "        self.perplejidad = list()\n",
    "        \n",
    "    def getTrainValidSplits(self, split):\n",
    "        ini = (split)*self.sizeSplit\n",
    "        fin = (split + 1)*self.sizeSplit\n",
    "        \n",
    "        if split > 0 and split<self.split-1:\n",
    "            train_split = self.indexes[0:ini] + self.indexes[fin:]\n",
    "            validation_split = self.indexes[ini:fin]\n",
    "        elif split == 0 :\n",
    "            train_split = self.indexes[fin:]\n",
    "            validation_split = self.indexes[0:fin]\n",
    "        else:\n",
    "            train_split = self.indexes[0:ini]\n",
    "            validation_split = self.indexes[ini:]\n",
    "        #Solo para debug\n",
    "        #self.validation_split = validation_split\n",
    "        #self.train_split = train_split\n",
    "        \n",
    "        return train_split, validation_split\n",
    "            \n",
    "    def loadModel(self,file='model.pk'):\n",
    "        with open(file,'rb') as model_file:\n",
    "            self.weigths = pickle.load(model_file)\n",
    "            self.bias = pickle.load(model_file)\n",
    "        print('¡Modelo cargado correctamente!')\n",
    "    \n",
    "    def export(self,file='model_2.pk'):\n",
    "        with open(file,'wb') as model_file:\n",
    "            pickle.dump(self.weigths, model_file)\n",
    "            pickle.dump(self.bias, model_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1cacf048",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Corpus.pk','rb') as corpus_file:\n",
    "    dic_words = pickle.load(corpus_file)\n",
    "    dic_index = pickle.load(corpus_file)\n",
    "    vocabulario = pickle.load(corpus_file)\n",
    "    bigrams = pickle.load(corpus_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867290b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.validation_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "48624ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Modelo cargado correctamente!\n",
      "Epoch: 0  fold:  1  iteración:  5000  /  22504\n",
      "Epoch: 0  fold:  1  iteración:  10000  /  22504\n",
      "Epoch: 0  fold:  1  iteración:  15000  /  22504\n",
      "Epoch: 0  fold:  1  iteración:  20000  /  22504\n",
      "Perplejidad:  inf \n",
      "\n",
      "Epoch: 0  fold:  2  iteración:  5000  /  22504\n",
      "Epoch: 0  fold:  2  iteración:  10000  /  22504\n",
      "Epoch: 0  fold:  2  iteración:  15000  /  22504\n",
      "Epoch: 0  fold:  2  iteración:  20000  /  22504\n",
      "Perplejidad:  inf \n",
      "\n",
      "Epoch: 0  fold:  3  iteración:  5000  /  22504\n",
      "Epoch: 0  fold:  3  iteración:  10000  /  22504\n",
      "Epoch: 0  fold:  3  iteración:  15000  /  22504\n",
      "Epoch: 0  fold:  3  iteración:  20000  /  22504\n",
      "Perplejidad:  inf \n",
      "\n",
      "Epoch: 0  fold:  4  iteración:  5000  /  22504\n",
      "Epoch: 0  fold:  4  iteración:  10000  /  22504\n",
      "Epoch: 0  fold:  4  iteración:  15000  /  22504\n",
      "Epoch: 0  fold:  4  iteración:  20000  /  22504\n",
      "Perplejidad:  inf \n",
      "\n",
      "Epoch: 0  fold:  5  iteración:  5000  /  22500\n",
      "Epoch: 0  fold:  5  iteración:  10000  /  22500\n",
      "Epoch: 0  fold:  5  iteración:  15000  /  22500\n",
      "Epoch: 0  fold:  5  iteración:  20000  /  22500\n",
      "Perplejidad:  inf \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim = len(vocabulario)\n",
    "model = ModeloB(dim, [100 , 300], dim, 0.02) #Más alto de 0.1 hace que no converga\n",
    "model.loadData(bigrams, dim)\n",
    "model.loadModel('model_13.pk')\n",
    "model.train(10)\n",
    "model.export('model_23.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840551e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export('model_3.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "aa186077",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModeloB' object has no attribute 'prediciones'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2314/638254437.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#p.pprint(list(model.prediciones))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediciones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediciones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#model._fordward(5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ModeloB' object has no attribute 'prediciones'"
     ]
    }
   ],
   "source": [
    "import pprint as p\n",
    "#p.pprint(list(model.prediciones))\n",
    "p.pprint(list(1/model.prediciones[:5]))\n",
    "print(np.prod(1/model.prediciones[:5]))\n",
    "#model._fordward(5)\n",
    "#model._backward(1,5)\n",
    "\n",
    "#for m,h in zip(model.weigths,model.Hs):\n",
    "    #print(m.shape,h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cd7185cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0329704789394227,\n",
      " 449.133848877946,\n",
      " 1.0000040964968162,\n",
      " 45.88753392084974,\n",
      " 2.775725950143549,\n",
      " 187.6371349020139,\n",
      " 2.710478521783928,\n",
      " 1.027218204273413,\n",
      " 5.708444824854162,\n",
      " 1279.7745355590105]\n",
      "225535817781.74835\n"
     ]
    }
   ],
   "source": [
    "p.pprint(list(1/model.prediciones[:10]))\n",
    "print(np.prod(1/model.prediciones[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "93310a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('no', 0.13763450033515712),\n",
       " ('me', 0.08761853936088525),\n",
       " ('es', 0.056657394342152494),\n",
       " ('_EOS_', 0.03846127078922387),\n",
       " ('que', 0.0339624480540481),\n",
       " ('hasta', 0.030048298071716096),\n",
       " ('ya', 0.028184453520051396),\n",
       " ('y', 0.027752348732223434),\n",
       " ('a', 0.0232806070911602),\n",
       " ('de', 0.02294203147317707),\n",
       " ('si', 0.019754915377732957),\n",
       " ('tengo', 0.019483435508565163),\n",
       " ('con', 0.018708560823158027),\n",
       " ('se', 0.01797349216416634),\n",
       " ('en', 0.015888192672174124)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabra = dic_words['pero']\n",
    "prediccion = model.predic(palabra)\n",
    "#print(dic_index)\n",
    "lis = [(dic_index[idx],prob) for idx,prob in zip (range(len(prediccion.T[0])-1),prediccion.T[0])]\n",
    "sorted(lis, key = lambda x: x[1], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a9da51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 8] [3 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8359588020779368"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,2,3,4,5,6])\n",
    "print(x[0:2]+x[4:],x[2:4])\n",
    "\n",
    "np.prod(1/x[:3])**(0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
