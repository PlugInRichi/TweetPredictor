{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b719c6a5",
   "metadata": {},
   "source": [
    "# Definición de la Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0387c82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70ddd2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModeloB:\n",
    "    \n",
    "    def __init__(self, dim_in  = 2, h_layers = [3 , 5], dim_out = 2, lr = 0.02):\n",
    "        np.random.seed(505) #Establecida para experimentación\n",
    "        self.dim_in  = dim_in # Dimensión de la entrada\n",
    "        self.dim_h_layers = len(h_layers) # Número de capas ocultas\n",
    "        self.dim_out = dim_out # Dimensión capa de salida\n",
    "\n",
    "        self.lr = lr #Learning Reate\n",
    "\n",
    "        self.layers = h_layers\n",
    "        \n",
    "        self.layers.insert(0,dim_in)\n",
    "        self.layers.append(dim_out)\n",
    "\n",
    "        self.ident = lambda x : x\n",
    "        self.tanh = lambda x : np.tanh(x)\n",
    "        self.soft_max = lambda x : np.exp(x - np.max(x))/np.exp(x - np.max(x)).sum(0, keepdims=True) #Cero porque son vectores columna\n",
    "\n",
    "        self.weigths = list() #Der*Izq\n",
    "        self.bias = list()\n",
    "        self.Hs = list()\n",
    "\n",
    "        for k in range(self.dim_h_layers + 1):\n",
    "            self.weigths.append(np.random.rand(self.layers[k+1],self.layers[k])/np.sqrt(self.layers[k+1]))#Pa que converja rápido\n",
    "            self.bias.append(np.ones((self.layers[k+1],1)))\n",
    "            self.Hs.append(np.zeros((self.layers[k+1],1)))\n",
    "\n",
    "    def _backward(self,y_idx,x_idx):\n",
    "        y = np.zeros((self.sizeVocaculary,1))\n",
    "        y[y_idx] = 1\n",
    "\n",
    "        d_salida = self.Hs[-1] - y\n",
    "        d_hidden =(1 - self.Hs[-2]**2) * np.dot(self.weigths[-1].T,d_salida)\n",
    "        d_embedd =  np.dot(self.weigths[-2].T,d_hidden)\n",
    "\n",
    "        #Actualización de pesos\n",
    "        #self.weigths[-1] -=  self.lr * np.dot(d_salida,self.Hs[-2].T)\n",
    "        #self.weigths[-2] -=  self.lr * np.dot(d_hidden,self.Hs[-3].T)\n",
    "        self.weigths[-1] -=  self.lr * np.outer(d_salida,self.Hs[-2])\n",
    "        self.weigths[-2] -=  self.lr * np.outer(d_hidden,self.Hs[-3])\n",
    "        self.weigths[-3][:,x_idx] -= self.lr * d_embedd.reshape(-1) \n",
    "\n",
    "        #Actualización de bias\n",
    "        self.bias[-1] = self.bias[-1] - self.lr * d_salida\n",
    "        self.bias[-2] = self.bias[-2] - self.lr * d_hidden\n",
    "\n",
    "    def _fordward(self, x):\n",
    "        #Obtiene el embedding\n",
    "        self.Hs[0] = self.weigths[0][:,x].reshape((100,1))\n",
    "        #Capa oculta\n",
    "        self.Hs[1] = self.tanh(np.dot(self.weigths[1],self.Hs[0]) + self.bias[1])\n",
    "        #Predicción\n",
    "        self.Hs[2] = self.soft_max(np.dot(self.weigths[2],self.Hs[1]) + self.bias[2])\n",
    "        \n",
    "    def train(self, epochs = 1):\n",
    "        for i in range(epochs):\n",
    "            count = 0 \n",
    "            for k in self.train_split:\n",
    "                self._fordward(self.bigrams[k][0])\n",
    "                self._backward(self.bigrams[k][1],self.bigrams[k][0])\n",
    "                count += 1 \n",
    "                if (count%1000 == 0):\n",
    "                  print('Epoca: ',i,' iteración: ',k,' / ',self.sizeData)    \n",
    "            \n",
    "    def predic(self, x):\n",
    "        self._fordward(self.bigrams[k][0])\n",
    "        \n",
    "    def loadData(self, bigrams, sizeVocaculary):\n",
    "        self.bigrams = bigrams\n",
    "        self.sizeData = len(bigrams)\n",
    "        self.sizeVocaculary = sizeVocaculary\n",
    "        self.buildTrainValidationSplits(bigrams, 0.3)\n",
    "        \n",
    "    def buildTrainValidationSplits(self,bigrams, validation_split = 0.3):\n",
    "        indexes = [i for i in range (len (bigrams))]\n",
    "        #shuffle(indexes) #Mezclamos los datos \n",
    "        split = int(len(bigrams)*0.3)\n",
    "        #self.train = idx_sh[idx_sh:]\n",
    "        #self.validation = idx_sh[:idx_sh]\n",
    "        self.train_split = indexes\n",
    "            \n",
    "    def loadModel(self,file='model.pk'):\n",
    "        with open('model.pk','rb') as model_file:\n",
    "            self.weigths = pickle.load(model_file)\n",
    "            self.bias = pickle.load(model_file)\n",
    "        print('¡Modelo cargado correctamente!')\n",
    "    \n",
    "    def export(self,file='model_2.pk'):\n",
    "        with open(file,'wb') as model_file:\n",
    "            pickle.dump(self.weigths, model_file)\n",
    "            pickle.dump(self.bias, model_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cacf048",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Corpus.pk','rb') as corpus_file:\n",
    "    dic_words = pickle.load(corpus_file)\n",
    "    dic_index = pickle.load(corpus_file)\n",
    "    vocabulario = pickle.load(corpus_file)\n",
    "    bigrams = pickle.load(corpus_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48624ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca:  0  iteración:  999  /  28129\n",
      "Epoca:  0  iteración:  1999  /  28129\n",
      "Epoca:  0  iteración:  2999  /  28129\n",
      "Epoca:  0  iteración:  3999  /  28129\n",
      "Epoca:  0  iteración:  4999  /  28129\n",
      "Epoca:  0  iteración:  5999  /  28129\n",
      "Epoca:  0  iteración:  6999  /  28129\n",
      "Epoca:  0  iteración:  7999  /  28129\n",
      "Epoca:  0  iteración:  8999  /  28129\n",
      "Epoca:  0  iteración:  9999  /  28129\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2314/2697126681.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModeloB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2314/3232230684.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_split\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fordward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2314/3232230684.py\u001b[0m in \u001b[0;36m_fordward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweigths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m#Capa oculta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweigths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;31m#Predicción\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoft_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweigths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dim = len(vocabulario)\n",
    "model = ModeloB(dim, [100 , 300], dim, 0.2)\n",
    "model.loadData(bigrams, dim)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa186077",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model._fordward(5)\n",
    "#model._backward(1,5)\n",
    "\n",
    "#for m,h in zip(model.weigths,model.Hs):\n",
    "    #print(m.shape,h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9da51d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
